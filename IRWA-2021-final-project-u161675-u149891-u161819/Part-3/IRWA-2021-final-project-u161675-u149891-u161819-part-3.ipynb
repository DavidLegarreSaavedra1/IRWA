{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "w-6WfEAfgKfW",
    "outputId": "fdb1b1c7-189d-4489-e69f-5ef378785780"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\David\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\David\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"lightgreen\">0.1 Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "U2X9M6uVgKfa",
    "outputId": "572a88c4-dd3b-4adf-8516-91053fdf7f9d"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import time\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import smart_open\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkN98nE2gKfb"
   },
   "source": [
    "<font size=\"+5\" color=\"seagreen\">1. Text Processing</font>\n",
    "\n",
    "\n",
    "<font size=\"+2\" color=\"lightgreen\">1.1 Read the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1sVTG9ergKfe"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This dataset consists only of one line where all the 2399 tweets by the WHO twitter account. \n",
    "We use the json python library to load this text as a dictionary since the dataset is stored \n",
    "in JSON format. \n",
    "\"\"\"\n",
    "docs_path = 'dataset_tweets_WHO.txt'\n",
    "with open(docs_path) as fp:\n",
    "    lines = fp.readline()\n",
    "tweets = json.loads(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\" color=\"greenyellow\">Here we've placed a print in order to ckeck the structure the tweets follow </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LWRFRUj6gKfe",
    "outputId": "3a096794-da46-4de8-f900-2674f41fa5cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First tweet structure:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Wed Oct 13 09:15:58 +0000 2021',\n",
       " 'id': 1448215930178310144,\n",
       " 'id_str': '1448215930178310144',\n",
       " 'full_text': \"It's International Day for Disaster Risk Reduction\\n\\n#OpenWHO has launched a multi-tiered core curriculum to help equip you with the competencies needed to work within public health emergency response.\\n\\nStart learning today &amp; be #Ready4Response:\\nüëâ https://t.co/hBFFOF0xKL https://t.co/fgZY22RWuS\",\n",
       " 'truncated': False,\n",
       " 'display_text_range': [0, 274],\n",
       " 'entities': {'hashtags': [{'text': 'OpenWHO', 'indices': [52, 60]},\n",
       "   {'text': 'Ready4Response', 'indices': [232, 247]}],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [],\n",
       "  'urls': [{'url': 'https://t.co/hBFFOF0xKL',\n",
       "    'expanded_url': 'https://bit.ly/3wCa0Dr',\n",
       "    'display_url': 'bit.ly/3wCa0Dr',\n",
       "    'indices': [251, 274]}],\n",
       "  'media': [{'id': 1448215398814560259,\n",
       "    'id_str': '1448215398814560259',\n",
       "    'indices': [275, 298],\n",
       "    'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/1448215398814560259/pu/img/0COksfUiCnS3MuNy.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/1448215398814560259/pu/img/0COksfUiCnS3MuNy.jpg',\n",
       "    'url': 'https://t.co/fgZY22RWuS',\n",
       "    'display_url': 'pic.twitter.com/fgZY22RWuS',\n",
       "    'expanded_url': 'https://twitter.com/WHO/status/1448215930178310144/video/1',\n",
       "    'type': 'photo',\n",
       "    'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "     'large': {'w': 1920, 'h': 1080, 'resize': 'fit'},\n",
       "     'medium': {'w': 1200, 'h': 675, 'resize': 'fit'},\n",
       "     'small': {'w': 680, 'h': 383, 'resize': 'fit'}}}]},\n",
       " 'extended_entities': {'media': [{'id': 1448215398814560259,\n",
       "    'id_str': '1448215398814560259',\n",
       "    'indices': [275, 298],\n",
       "    'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/1448215398814560259/pu/img/0COksfUiCnS3MuNy.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/1448215398814560259/pu/img/0COksfUiCnS3MuNy.jpg',\n",
       "    'url': 'https://t.co/fgZY22RWuS',\n",
       "    'display_url': 'pic.twitter.com/fgZY22RWuS',\n",
       "    'expanded_url': 'https://twitter.com/WHO/status/1448215930178310144/video/1',\n",
       "    'type': 'video',\n",
       "    'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "     'large': {'w': 1920, 'h': 1080, 'resize': 'fit'},\n",
       "     'medium': {'w': 1200, 'h': 675, 'resize': 'fit'},\n",
       "     'small': {'w': 680, 'h': 383, 'resize': 'fit'}},\n",
       "    'video_info': {'aspect_ratio': [16, 9],\n",
       "     'duration_millis': 97639,\n",
       "     'variants': [{'bitrate': 256000,\n",
       "       'content_type': 'video/mp4',\n",
       "       'url': 'https://video.twimg.com/ext_tw_video/1448215398814560259/pu/vid/480x270/izK3M-OCh-xYweXi.mp4?tag=12'},\n",
       "      {'bitrate': 832000,\n",
       "       'content_type': 'video/mp4',\n",
       "       'url': 'https://video.twimg.com/ext_tw_video/1448215398814560259/pu/vid/640x360/deOwD7OuDaJ7uiHk.mp4?tag=12'},\n",
       "      {'bitrate': 2176000,\n",
       "       'content_type': 'video/mp4',\n",
       "       'url': 'https://video.twimg.com/ext_tw_video/1448215398814560259/pu/vid/1280x720/aOPOcEVxPItrZ2RR.mp4?tag=12'},\n",
       "      {'content_type': 'application/x-mpegURL',\n",
       "       'url': 'https://video.twimg.com/ext_tw_video/1448215398814560259/pu/pl/4_kPEePepwPbCe8k.m3u8?tag=12&container=fmp4'}]},\n",
       "    'additional_media_info': {'monetizable': False}}]},\n",
       " 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       " 'in_reply_to_status_id': 1448208458604584960,\n",
       " 'in_reply_to_status_id_str': '1448208458604584960',\n",
       " 'in_reply_to_user_id': 14499829,\n",
       " 'in_reply_to_user_id_str': '14499829',\n",
       " 'in_reply_to_screen_name': 'WHO',\n",
       " 'user': {'id': 14499829,\n",
       "  'id_str': '14499829',\n",
       "  'name': 'World Health Organization (WHO)',\n",
       "  'screen_name': 'WHO',\n",
       "  'location': 'Geneva, Switzerland',\n",
       "  'description': 'We are the #UnitedNations‚Äô health agency - #HealthForAll.\\n‚ñ∂Ô∏è Always check our latest tweets on #COVID19 for updated advice/information.',\n",
       "  'url': 'https://t.co/wVulKuROWG',\n",
       "  'entities': {'url': {'urls': [{'url': 'https://t.co/wVulKuROWG',\n",
       "      'expanded_url': 'http://www.who.int',\n",
       "      'display_url': 'who.int',\n",
       "      'indices': [0, 23]}]},\n",
       "   'description': {'urls': []}},\n",
       "  'protected': False,\n",
       "  'followers_count': 9963586,\n",
       "  'friends_count': 1743,\n",
       "  'listed_count': 34215,\n",
       "  'created_at': 'Wed Apr 23 19:56:27 +0000 2008',\n",
       "  'favourites_count': 11879,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'verified': True,\n",
       "  'statuses_count': 64983,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': False,\n",
       "  'profile_background_color': 'D0ECF8',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': True,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/875476478988886016/_l61qZdR_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/875476478988886016/_l61qZdR_normal.jpg',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/14499829/1610970935',\n",
       "  'profile_link_color': '0396DB',\n",
       "  'profile_sidebar_border_color': '8C8C8C',\n",
       "  'profile_sidebar_fill_color': 'D9D9D9',\n",
       "  'profile_text_color': '000000',\n",
       "  'profile_use_background_image': True,\n",
       "  'has_extended_profile': True,\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': False,\n",
       "  'follow_request_sent': False,\n",
       "  'notifications': False,\n",
       "  'translator_type': 'regular',\n",
       "  'withheld_in_countries': []},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 16,\n",
       " 'favorite_count': 52,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First tweet structure:\")\n",
    "tweets['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\" color=\"greenyellow\">Here we've placed a print in order to ckeck the keys of a tweet</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "i9cItST3gKff",
    "outputId": "9a2c14d5-2f54-4c41-d4d8-49de1b5c8722"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'extended_entities', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['0'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\" color=\"greenyellow\">In order to check that the results of our future trials, we print the text of the firsnt 3 tweets </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HfQUpROHgKfg",
    "outputId": "0a977b4d-2140-4cc9-e84d-c721cbc31f88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three full text tweets:\n",
      "\n",
      "Tweet number 1 :\n",
      "\n",
      "It's International Day for Disaster Risk Reduction\n",
      "\n",
      "#OpenWHO has launched a multi-tiered core curriculum to help equip you with the competencies needed to work within public health emergency response.\n",
      "\n",
      "Start learning today &amp; be #Ready4Response:\n",
      "üëâ https://t.co/hBFFOF0xKL https://t.co/fgZY22RWuS\n",
      "\n",
      "\n",
      "Tweet number 2 :\n",
      "\n",
      "#COVID19 has shown how health emergencies and disasters affect entire communities ‚Äì especially those with weak health systems, and vulnerable populations like migrants, indigenous peoples, and those living in fragile humanitarian conditions. https://t.co/jpUQpnu0V1\n",
      "\n",
      "\n",
      "Tweet number 3 :\n",
      "\n",
      "It's International Day for Disaster Risk Reduction\n",
      " \n",
      "To better respond to emergencies countries must:\n",
      "‚úÖ invest in health care systems\n",
      "‚úÖ achieve gender equity\n",
      "‚úÖ protect marginalised groups\n",
      "‚úÖ ensure ready &amp; equitable access to supplies\n",
      " \n",
      "A strong &amp; resilient health system is üîë https://t.co/5NALyjIymp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"First three full text tweets:\\n\")\n",
    "for i in range(3):\n",
    "    print(\"Tweet number\",i+1,\":\\n\")\n",
    "    print(tweets[str(i)][\"full_text\"])\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"lightgreen\">1.2 Process tweets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oPL1_b7cgKfh"
   },
   "outputs": [],
   "source": [
    "def process_tweet(line):\n",
    "    \"\"\"\n",
    "    Pre-process the tweet text removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be pre-processed\n",
    "    \n",
    "    Returns:\n",
    "    line - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    line = line.lower() # Transform in lowercase\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    line = tokenizer.tokenize(line)\n",
    "    line = [word for word in line if word not in stop_words]  #eliminate the stopwords \n",
    "    line = [stemmer.stem(word) for word in line] #perform stemming \n",
    "    i = 0\n",
    "    for word in line:\n",
    "        if word[0:4] == 'http':\n",
    "            line = line[:i]\n",
    "        i+=1\n",
    "    ## END CODE\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "144IS041gKfh"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here for every tweet we extract the 'full_text' variable since we will only \n",
    "search inside the text of each tweet. Thus, we pre-process each tweet and \n",
    "store it in a new dictionary called proc_tweets for later use\n",
    "\"\"\"\n",
    "proc_tweets = {}\n",
    "for tweet_id, tweet in zip(tweets.keys(),tweets.values()):\n",
    "    proc_tweets[int(tweet_id)] = process_tweet(tweet['full_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\" color=\"greenyellow\">Print of the processed tweets to check that our function works</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Tg3RKvwhgKfi",
    "outputId": "489ad43b-c725-41ec-b4a2-e6b689c721da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five processed tweets\n",
      "\n",
      "['intern', 'day', 'disast', 'risk', 'reduct', 'openwho', 'launch', 'multi', 'tier', 'core', 'curriculum', 'help', 'equip', 'compet', 'need', 'work', 'within', 'public', 'health', 'emerg', 'respons', 'start', 'learn', 'today', 'amp', 'ready4respons']\n",
      "\n",
      "\n",
      "['covid19', 'shown', 'health', 'emerg', 'disast', 'affect', 'entir', 'commun', 'especi', 'weak', 'health', 'system', 'vulner', 'popul', 'like', 'migrant', 'indigen', 'peopl', 'live', 'fragil', 'humanitarian', 'condit']\n",
      "\n",
      "\n",
      "['intern', 'day', 'disast', 'risk', 'reduct', 'better', 'respond', 'emerg', 'countri', 'must', 'invest', 'health', 'care', 'system', 'achiev', 'gender', 'equiti', 'protect', 'marginalis', 'group', 'ensur', 'readi', 'amp', 'equit', 'access', 'suppli', 'strong', 'amp', 'resili', 'health', 'system']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"First five processed tweets\\n\")\n",
    "for i in range(3):\n",
    "    print(proc_tweets[i])\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWvhi_3ngKfm"
   },
   "source": [
    "<font size=\"+5\" color=\"seagreen\">2. Indexing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "quq0_sRWgKfm"
   },
   "outputs": [],
   "source": [
    "def get_tweet_info(tweet, tweet_id):\n",
    "    Tweet = tweet['full_text']\n",
    "    Username = tweet['user']['name']\n",
    "    Date = tweet['created_at']\n",
    "    Hashtags = []\n",
    "    hashtags_list = tweet['entities']['hashtags']\n",
    "    for hashtag in hashtags_list:\n",
    "        Hashtags.append(hashtag['text'])\n",
    "    Likes = tweet['favorite_count']\n",
    "    Retweets = tweet['retweet_count']\n",
    "    Url = f\"https://twitter.com/{tweet['user']['screen_name']}/status/{tweet['id_str']}\"\n",
    "    info = [Tweet, Username, Date, Hashtags, Likes, Retweets, Url, tweet_id]    \n",
    "    return info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Df12HXydgKfn"
   },
   "outputs": [],
   "source": [
    "def create_index(tweets):\n",
    "    \"\"\"\n",
    "    Generates the index from our database to perform queries from\n",
    "    \n",
    "    Argument:\n",
    "    tweets -- collection of tweets\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of documents where these keys appears in as values.\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "    id_index = {}\n",
    "    tf = {}\n",
    "    df = defaultdict(int)\n",
    "    idf = defaultdict(float)\n",
    "    numDocuments = len(tweets)\n",
    "    for i in range(numDocuments):\n",
    "        tweet = tweets[str(i)]\n",
    "        terms = process_tweet(tweet['full_text']) #get tweet text\n",
    "        id_tweet = tweet['id']\n",
    "        info = get_tweet_info(tweet, id_tweet) # get \"document\" info\n",
    "        id_index[id_tweet]=info\n",
    "        \n",
    "        for term in terms: \n",
    "            try:\n",
    "                index[term].append(id_tweet)  \n",
    "                \n",
    "            except:\n",
    "                index[term]= [id_tweet]\n",
    "            \n",
    "        norm=0\n",
    "        for term,ids in index.items():\n",
    "            norm += len(ids)**2\n",
    "        norm = math.sqrt(norm)\n",
    "        \n",
    "        for term,ids in index.items():\n",
    "            if term in tf:\n",
    "                tf[term][id_tweet] = np.round(len(ids)/norm,4)\n",
    "            else:\n",
    "                tf[term] = {id_tweet:np.round(len(ids)/norm,4)}\n",
    "            df[term] += 1\n",
    "        \n",
    "        for term in index:\n",
    "            idf[term] = np.round(np.log(float(numDocuments/df[term])),4)\n",
    "        \n",
    "    return index, tf,df,idf,id_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "x2EDaYLAgKfo",
    "outputId": "b9adcb85-8613-44ea-ab4f-bd97586161bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create the index: 222.03 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "index, tf,df,idf,id_index = create_index(tweets)\n",
    "print(\"Total time to create the index: {} seconds\".format(np.round(time.time() - start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index.pkl', 'wb') as index_file:\n",
    "    pickle.dump(index, index_file)\n",
    "    \n",
    "with open('tf.pkl', 'wb') as tf_file:\n",
    "    pickle.dump(tf, tf_file)\n",
    "\n",
    "with open('df.pkl', 'wb') as df_file:\n",
    "    pickle.dump(df, df_file)\n",
    "\n",
    "with open('idf.pkl', 'wb') as idf_file:\n",
    "    pickle.dump(idf, idf_file)\n",
    "    \n",
    "with open('id_index.pkl', 'wb') as id_index_file:\n",
    "    pickle.dump(id_index, id_index_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wSOwTs6lgKfp"
   },
   "outputs": [],
   "source": [
    "def rank_documents(terms, docs, index, idf, tf, title_index):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    title_index -- mapping between page id and page title\n",
    "    \n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) \n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms) \n",
    "\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        # Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]=query_terms_count[term]/query_norm * idf[term] \n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc in index[term]:          \n",
    "            if doc in docs:\n",
    "                doc_vectors[doc][termIndex] = tf[term][doc] * idf[term]\n",
    "\n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "        query = input()\n",
    "        if not query:\n",
    "            return None\n",
    "        result_docs, doc_scores = search_tf_idf(query, index)\n",
    "    return result_docs, doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ND8CkxgegKfq"
   },
   "outputs": [],
   "source": [
    "def search_tf_idf(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    first = True\n",
    "    if not query:\n",
    "        return None\n",
    "    for term in query:\n",
    "        try:\n",
    "            list_docs = index[term]\n",
    "            if first:\n",
    "                docs = set(list_docs)\n",
    "                first = False\n",
    "            else:\n",
    "                docs &= set(list_docs)\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    docs = list(docs)\n",
    "    ranked_docs, doc_scores = rank_documents(query, docs, index, idf, tf, id_index)\n",
    "    \n",
    "    return ranked_docs, doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "JBqDgm58gKfq",
    "outputId": "1a471fa1-e843-44cd-e5f7-c6e7ddac98ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query (i.e.: Computer Science):\n",
      "\n",
      "\n",
      "======================\n",
      "Top 20 results out of 13 for the searched query (Covid vaccine):\n",
      "\n",
      "[\"RT @WHOAFRO: Join tomorrow's media briefing on the #COVID19 pandemic &amp; the global 10% COVID-19 vaccination milestones reached by countries‚Ä¶\", 'World Health Organization (WHO)', 'Wed Sep 29 19:01:27 +0000 2021', ['COVID19'], 0, 21, 'https://twitter.com/WHO/status/1443289841698025473', 1443289841698025473]\n",
      "\n",
      "['RT @WHOAFRO: üì∫ LIVE: @WHOAFRO media briefing on the #COVID19 pandemic &amp; the global 10% COVID-19 vaccination milestones reached by countries‚Ä¶', 'World Health Organization (WHO)', 'Thu Sep 30 10:07:43 +0000 2021', ['COVID19'], 0, 27, 'https://twitter.com/WHO/status/1443517908072730624', 1443517908072730624]\n",
      "\n",
      "['Q&amp;A #AskWHO on COVID-19 vaccines effectiveness https://t.co/FEdfOREhjn', 'World Health Organization (WHO)', 'Wed Jun 30 16:12:43 +0000 2021', ['AskWHO'], 219, 85, 'https://twitter.com/WHO/status/1410270080873598979', 1410270080873598979]\n",
      "\n",
      "['The heads of the four organizations discussed the urgency of increasing supplies of #COVID19 vaccines, therapeutics and diagnostics for developing countries; and practical &amp; effective ways to track, coordinate and advance delivery of COVID-19 vaccines to developing countries. https://t.co/fpISmcwQc2', 'World Health Organization (WHO)', 'Wed Jun 30 20:04:47 +0000 2021', ['COVID19'], 67, 17, 'https://twitter.com/WHO/status/1410328481335029765', 1410328481335029765]\n",
      "\n",
      "['COVID-19 vaccine inequity is undermining üåç economic recovery. üÜïWHO, @UNDP and @BlavatnikSchool Dashboard on #VaccinEquity finds that low-income countries would add $38B to their GDP forecast if they had the same vaccination rate as high-income countries\\nhttps://t.co/BsYF2eYL1G', 'World Health Organization (WHO)', 'Thu Jul 22 13:43:53 +0000 2021', ['VaccinEquity'], 383, 168, 'https://twitter.com/WHO/status/1418205159188955137', 1418205159188955137]\n",
      "\n",
      "['Are you involved in the costing, budgeting or financing processes of #COVID19 vaccine delivery in your country?\\n\\nJoin our üÜï #OpenWHO course to learn how to use the COVID-19 Vaccine Introduction and deployment Costing Tool.\\n\\nüëâ https://t.co/vyXfuxXSDB https://t.co/XPr1caIFg6', 'World Health Organization (WHO)', 'Mon Aug 02 10:46:05 +0000 2021', ['COVID19', 'OpenWHO'], 146, 31, 'https://twitter.com/WHO/status/1422146679051067400', 1422146679051067400]\n",
      "\n",
      "['Richer countries are projected to both vaccinate &amp; recover quicker from #COVID19. Poorer countries haven‚Äôt even been able to vaccinate their health workers &amp; most at-risk populations, and may not achieve pre-COVID-19 levels of growth until 2024. \\n\\nhttps://t.co/48frkTNNmC https://t.co/SuItOFgaxZ', 'World Health Organization (WHO)', 'Thu Jul 22 15:20:11 +0000 2021', ['COVID19'], 130, 65, 'https://twitter.com/WHO/status/1418229392514424836', 1418229392514424836]\n",
      "\n",
      "['üíâüíâüíâüíâ\\nüíâüíâüíâüíâ\\nüíâüíâüíâüíâ\\nüíâüíâüíâüíâ\\nüíâüíâüíâüíâ                 üíâüíâüíâüíâ\\nüíâüíâüíâüíâ                 üíâüíâüíâüíâ\\n\\nCOVID-19 vaccines     COVID-19 vaccines\\nin 10 countries             in the rest of the üåç\\n\\n#VaccinEquity is üóùÔ∏è to ending the pandemic, together!\\n\\n#WorldEmojiDay', 'World Health Organization (WHO)', 'Sat Jul 17 16:24:23 +0000 2021', ['VaccinEquity', 'WorldEmojiDay'], 3486, 1517, 'https://twitter.com/WHO/status/1416433609091653633', 1416433609091653633]\n",
      "\n",
      "[\"RT @WHONepal: Nepal has administered more than üîümillion doses of COVID-19 üíâüíâüíâ, fully vaccinating 15% of its population. This feat wouldn't‚Ä¶\", 'World Health Organization (WHO)', 'Thu Sep 02 16:38:12 +0000 2021', [], 0, 101, 'https://twitter.com/WHO/status/1433469315710341130', 1433469315710341130]\n",
      "\n",
      "['#COVID19 variants &amp; vaccines:\\n\\n‚úÖ COVID-19 vaccines provide strong protection against serious illness &amp; death\\n‚úÖ Get all necessary doses to develop maximum protection\\n‚úÖ Continue practicing all the protective behaviours even after vaccination to stop COVID-19 variants', 'World Health Organization (WHO)', 'Mon Sep 06 08:09:59 +0000 2021', ['COVID19'], 352, 169, 'https://twitter.com/WHO/status/1434790971632336906', 1434790971632336906]\n",
      "\n",
      "[\"Getting vaccinated against #COVID19 helps protect you from getting sick. As soon as it's your turn, take your vaccine!\\n\\nAll approved COVID-19 vaccines have been thoroughly tested, and all provide a high degree of protection against getting seriously ill &amp; dying from the disease. https://t.co/bYpU3WvpuM\", 'World Health Organization (WHO)', 'Sun Aug 15 06:01:21 +0000 2021', ['COVID19'], 299, 120, 'https://twitter.com/WHO/status/1426786068192366592', 1426786068192366592]\n",
      "\n",
      "['‚ñ∂Ô∏è If you have #COVID19, is it safe to breastfeed your baby‚ùì\\n\\n‚ñ∂Ô∏è Is it safe to get vaccinated against COVID-19 if you are breastfeeding‚ùì\\n\\n‚ñ∂Ô∏è How can you keep your baby safe while breastfeeding ü§± if you have COVID-19‚ùì\\n\\nDr Laurence Grummer-Strawn explains in #ScienceIn5. https://t.co/QMAq9TMY7A', 'World Health Organization (WHO)', 'Mon Aug 30 10:43:22 +0000 2021', ['COVID19', 'ScienceIn5'], 219, 105, 'https://twitter.com/WHO/status/1432292855037394953', 1432292855037394953]\n",
      "\n",
      "['RT @WHOPhilippines: Vaccines can‚Äôt stop #COVID19 alone, but by doing it all we can help protect ourselves and our loved ones against COVID-‚Ä¶', 'World Health Organization (WHO)', 'Mon Oct 11 04:39:10 +0000 2021', ['COVID19'], 0, 71, 'https://twitter.com/WHO/status/1447421491428143106', 1447421491428143106]\n",
      "\n",
      "\n",
      "======================\n",
      "Top 20 results out of 27 for the searched query (International health):\n",
      "\n",
      "[\"It's International Day for Disaster Risk Reduction\\n\\n#OpenWHO has launched a multi-tiered core curriculum to help equip you with the competencies needed to work within public health emergency response.\\n\\nStart learning today &amp; be #Ready4Response:\\nüëâ https://t.co/hBFFOF0xKL https://t.co/fgZY22RWuS\", 'World Health Organization (WHO)', 'Wed Oct 13 09:15:58 +0000 2021', ['OpenWHO', 'Ready4Response'], 52, 16, 'https://twitter.com/WHO/status/1448215930178310144', 1448215930178310144]\n",
      "\n",
      "[\"It's International Day for Disaster Risk Reduction\\n \\nTo better respond to emergencies countries must:\\n‚úÖ invest in health care systems\\n‚úÖ achieve gender equity\\n‚úÖ protect marginalised groups\\n‚úÖ ensure ready &amp; equitable access to supplies\\n \\nA strong &amp; resilient health system is üîë https://t.co/5NALyjIymp\", 'World Health Organization (WHO)', 'Wed Oct 13 07:53:28 +0000 2021', [], 300, 109, 'https://twitter.com/WHO/status/1448195167048118274', 1448195167048118274]\n",
      "\n",
      "['Today is International #DayOfTheGirl\\xa0!\\n\\xa0\\nWhen girls are able to\\n\\xa0\\nüëß make decisions\\nüëßüèø stay in school\\nüëßüèΩ prevent pregnancies\\nüëßüèª access health services equally,\\n\\xa0\\nthey can transform their future, and be the power of change.\\xa0\\nüëâhttps://t.co/79fBeDZFOx https://t.co/QCDYBtsTY7', 'World Health Organization (WHO)', 'Mon Oct 11 13:37:50 +0000 2021', ['DayOfTheGirl'], 1421, 622, 'https://twitter.com/WHO/status/1447557052147146752', 1447557052147146752]\n",
      "\n",
      "[\"It's International Day of Older Persons.\\n \\nHolding ageist attitudes towards older people results in their poorer physical and mental health and reduced quality of life, costing societies billions of dollars each year: https://t.co/FyffISMxvN\\n \\n#AWorld4AllAges https://t.co/Y7xU8SkygE\", 'World Health Organization (WHO)', 'Fri Oct 01 13:05:04 +0000 2021', ['AWorld4AllAges'], 197, 89, 'https://twitter.com/WHO/status/1443924928684826632', 1443924928684826632]\n",
      "\n",
      "[\"It's International #TranslationDay \\n\\nDid you know WHO offers üÜì online courses in 5‚É£6‚É£ languages on #COVID19 &amp; other health topics?\\n\\nStart learning in your language on our #OpenWHO platform today!\\nüëâhttps://t.co/6WYKcNolYP https://t.co/fi2LxxRnqz\", 'World Health Organization (WHO)', 'Thu Sep 30 11:14:41 +0000 2021', ['TranslationDay', 'COVID19', 'OpenWHO'], 194, 78, 'https://twitter.com/WHO/status/1443534762132582404', 1443534762132582404]\n",
      "\n",
      "['#France üá´üá∑ contributes to the #UHCPartnership, one of WHO‚Äôs largest initiatives for international cooperation for universal health coverage &amp; primary health care. It helps deliver WHO support &amp; technical expertise to 115 countries &amp; growing.\\nhttps://t.co/salgMpDpkF', 'World Health Organization (WHO)', 'Mon Sep 27 13:00:15 +0000 2021', ['France', 'UHCPartnership'], 58, 18, 'https://twitter.com/WHO/status/1442474165735407616', 1442474165735407616]\n",
      "\n",
      "[\"It's International Day of Sign Languages!\\n\\nOur free #OpenWHO learning platform has our #COVID19 course in Indian sign language to ensure no one is left behind. Everyone deserves access to health knowledge.\\n\\nüëâ https://t.co/K8kiuP8oz7 https://t.co/0rYB0PyKJ2\", 'World Health Organization (WHO)', 'Thu Sep 23 06:18:07 +0000 2021', ['OpenWHO', 'COVID19'], 156, 56, 'https://twitter.com/WHO/status/1440923415117017090', 1440923415117017090]\n",
      "\n",
      "['.@DrMikeRyan explains what are the criteria for calling off a pandemic and Public Health Emergency of International Concern ‚¨áÔ∏è https://t.co/WSjqMMumSc', 'World Health Organization (WHO)', 'Tue Sep 14 11:35:34 +0000 2021', [], 742, 391, 'https://twitter.com/WHO/status/1437741809753538561', 1437741809753538561]\n",
      "\n",
      "['@DrTedros @UNICEF @UN @WFP \"I thank the women and men of WHO‚Äôs national and international staff who continue to work every day to protect and promote the health of all #Afghanistan‚Äôs people\"-@DrTedros', 'World Health Organization (WHO)', 'Mon Sep 13 15:23:06 +0000 2021', ['Afghanistan'], 93, 25, 'https://twitter.com/WHO/status/1437436684023615495', 1437436684023615495]\n",
      "\n",
      "[\"It's International #LiteracyDay!\\n\\nOur free online learning platform #OpenWHO supports health literacy by giving #healthworkers equitable access to knowledge to protect themselves &amp; others from #COVID19.\\n\\nJoin us &amp; start learning today:\\nüëâhttps://t.co/ZWJ0i5hTKz https://t.co/fJXXEwI0Pm\", 'World Health Organization (WHO)', 'Wed Sep 08 09:40:22 +0000 2021', ['LiteracyDay', 'OpenWHO', 'healthworkers', 'COVID19'], 73, 28, 'https://twitter.com/WHO/status/1435538492503863299', 1435538492503863299]\n",
      "\n",
      "['\"‚úÖ They must ensure coherence with the International Health Regulations and other international instruments\\n\\n‚úÖ And they must be accountable.\"-@DrTedros \\nhttps://t.co/H2XbaPuhAa', 'World Health Organization (WHO)', 'Wed Aug 25 15:46:16 +0000 2021', [], 30, 11, 'https://twitter.com/WHO/status/1430557143170789380', 1430557143170789380]\n",
      "\n",
      "['@DrTedros @pahowho \"We\\'re particularly concerned about the health &amp; wellbeing of women &amp; girls. I call on the international community &amp; all actors to prioritise their access to all health services &amp; to safeguard their futures. We cannot backslide on two decades of progress\"-@DrTedros #Afghanistan', 'World Health Organization (WHO)', 'Wed Aug 18 13:36:40 +0000 2021', ['Afghanistan'], 81, 25, 'https://twitter.com/WHO/status/1427987816773046276', 1427987816773046276]\n",
      "\n",
      "[\"Nutrition ü•óüççü•ïüçÖ is essential for health and well-being at every stage of life.\\n \\nOn International #YouthDay &amp; everyday, let's help young people thrive by ensuring access to &amp; benefits from equitable food systems. üëâ https://t.co/KvTCXnRWoG https://t.co/VWP29gfUDb\", 'World Health Organization (WHO)', 'Thu Aug 12 09:46:27 +0000 2021', ['YouthDay'], 189, 63, 'https://twitter.com/WHO/status/1425755552664080390', 1425755552664080390]\n",
      "\n",
      "['\"At the World Health Assembly in May, Member States agreed to hold a Special Session of the Assembly in November to consider developing a WHO convention, agreement or other type of international instrument on pandemic preparedness and response.\"-@DrMikeRyan', 'World Health Organization (WHO)', 'Wed Jul 28 20:56:47 +0000 2021', [], 27, 7, 'https://twitter.com/WHO/status/1420488429180276751', 1420488429180276751]\n",
      "\n",
      "['\"All Member States must continue to strengthen the national core capacities called for under the International Health Regulations, so that they are functional and scalable when a pandemic occurs.\"-@DrMikeRyan', 'World Health Organization (WHO)', 'Wed Jul 28 20:50:23 +0000 2021', [], 11, 6, 'https://twitter.com/WHO/status/1420486820169756677', 1420486820169756677]\n",
      "\n",
      "['@DrTedros \"#Bahrain has also demonstrated its global solidarity, as one of the first countries in the Eastern Mediterranean region to join the ‚ÄúSolidarity Trial\", its award for women‚Äôs empowerment in health, and in hosting an international webinar on best practices in #COVID19\"-@DrTedros', 'World Health Organization (WHO)', 'Mon Jul 26 06:13:28 +0000 2021', ['Bahrain', 'COVID19'], 29, 8, 'https://twitter.com/WHO/status/1419541359107710976', 1419541359107710976]\n",
      "\n",
      "['By bringing together emergency actors, research &amp; academic institutions, and international &amp; national partners, INITIATE2 will\\n\\n‚úÖ develop solutions\\n‚úÖ test them in real-life scenarios\\n‚úÖ train logistics &amp; health responders how to apply them\\n\\nMore info üëâhttps://t.co/JbwmD86roc https://t.co/vPEr5qr8qu', 'World Health Organization (WHO)', 'Tue Jul 20 11:16:57 +0000 2021', [], 125, 28, 'https://twitter.com/WHO/status/1417443405337034752', 1417443405337034752]\n",
      "\n",
      "['@DrTedros @jensspahn @ACTAccelerator \"I also welcome #Germany‚Äôs support for the idea of an international #PandemicTreaty. Today, a working group of WHO Member States is meeting to consider this idea and others to strengthen global health security\"-@DrTedros', 'World Health Organization (WHO)', 'Thu Jul 15 12:26:17 +0000 2021', ['Germany', 'PandemicTreaty'], 68, 15, 'https://twitter.com/WHO/status/1415648915731386374', 1415648915731386374]\n",
      "\n",
      "['The Emergency Committee on #COVID19 reconvenes every 3 months to evaluate the evolution of the pandemic &amp; make recommendations to WHO &amp; countries on how to respond to the Public Health Emergency of International Concern.\\n\\nPrevious recommendations: https://t.co/cA4FCWWUqJ https://t.co/bmkZN64X50', 'World Health Organization (WHO)', 'Wed Jul 14 14:06:11 +0000 2021', ['COVID19'], 76, 28, 'https://twitter.com/WHO/status/1415311665801965568', 1415311665801965568]\n",
      "\n",
      "['Dr Didier Houssin is chairing the 8th International Health Regulations Emergency Committee on #COVID19.\\n\\nThe full list of the Committee members is available here:\\nhttps://t.co/Qtsxqkr7xi https://t.co/h5HTkvS8cS', 'World Health Organization (WHO)', 'Wed Jul 14 12:01:59 +0000 2021', ['COVID19'], 113, 22, 'https://twitter.com/WHO/status/1415280412650246149', 1415280412650246149]\n",
      "\n",
      "\n",
      "======================\n",
      "Top 20 results out of 10 for the searched query (Covid pandemics):\n",
      "\n",
      "['@DrTedros \"Although #VaccinEquity will help to end the pandemic, its effects will continue to be felt for many years ‚Äì especially for the people who have been infected and will continue to suffer from the effects of post #COVID19 condition, also known as ‚Äúlong COVID‚Äù\"-@DrTedros', 'World Health Organization (WHO)', 'Thu Oct 07 14:03:18 +0000 2021', ['VaccinEquity', 'COVID19'], 146, 37, 'https://twitter.com/WHO/status/1446113909480382464', 1446113909480382464]\n",
      "\n",
      "['üíâüíâüíâüíâ\\nüíâüíâüíâüíâ\\nüíâüíâüíâüíâ\\nüíâüíâüíâüíâ\\nüíâüíâüíâüíâ                 üíâüíâüíâüíâ\\nüíâüíâüíâüíâ                 üíâüíâüíâüíâ\\n\\nCOVID-19 vaccines     COVID-19 vaccines\\nin 10 countries             in the rest of the üåç\\n\\n#VaccinEquity is üóùÔ∏è to ending the pandemic, together!\\n\\n#WorldEmojiDay', 'World Health Organization (WHO)', 'Sat Jul 17 16:24:23 +0000 2021', ['VaccinEquity', 'WorldEmojiDay'], 3486, 1517, 'https://twitter.com/WHO/status/1416433609091653633', 1416433609091653633]\n",
      "\n",
      "['WHO continues to fight the #COVID19 pandemic, supporting and accelerating progress on #VaccinEquity in countries around the üåçüåéüåè.\\n\\nRead #WHOImpact stories to see how our donors &amp; partners help strengthen our COVID-19 response.üëâhttps://t.co/7hT3oHxDiG https://t.co/mnu6pnJB8U', 'World Health Organization (WHO)', 'Mon Aug 23 08:38:30 +0000 2021', ['COVID19', 'VaccinEquity', 'WHOImpact'], 171, 40, 'https://twitter.com/WHO/status/1429724718693634052', 1429724718693634052]\n",
      "\n",
      "[\"Young people will be the most affected by the long-term consequences of the #COVID19 pandemic, which will shape the üåèüåçüåé they live &amp; work in for decades to come.\\n\\nHere's how WHO &amp; partners help #YouthLead the charge to a brighter post-COVID future üëâhttps://t.co/c36ZMXNtA1 https://t.co/O6ei4mERy8\", 'World Health Organization (WHO)', 'Tue Aug 17 08:44:31 +0000 2021', ['COVID19', 'YouthLead'], 131, 44, 'https://twitter.com/WHO/status/1427551904498741250', 1427551904498741250]\n",
      "\n",
      "['RT @UNICEF: Your guide to breastfeeding safely during the COVID-19 pandemic. \\n\\n#WorldBreastfeedingWeek https://t.co/8EaLDselmn', 'World Health Organization (WHO)', 'Sun Aug 01 16:29:25 +0000 2021', ['WorldBreastfeedingWeek'], 0, 278, 'https://twitter.com/WHO/status/1421870697094205445', 1421870697094205445]\n",
      "\n",
      "[\"RT @WHOAFRO: Join tomorrow's media briefing on the #COVID19 pandemic &amp; the global 10% COVID-19 vaccination milestones reached by countries‚Ä¶\", 'World Health Organization (WHO)', 'Wed Sep 29 19:01:27 +0000 2021', ['COVID19'], 0, 21, 'https://twitter.com/WHO/status/1443289841698025473', 1443289841698025473]\n",
      "\n",
      "['RT @WHOAFRO: üì∫ LIVE: @WHOAFRO media briefing on the #COVID19 pandemic &amp; the global 10% COVID-19 vaccination milestones reached by countries‚Ä¶', 'World Health Organization (WHO)', 'Thu Sep 30 10:07:43 +0000 2021', ['COVID19'], 0, 27, 'https://twitter.com/WHO/status/1443517908072730624', 1443517908072730624]\n",
      "\n",
      "['üìô The new book aims to help children stay positive during the #COVID19 pandemic.\\nThe story is a sequel to the very well-received ‚ÄòMy Hero is You: how kids can fight COVID-19!‚Äô, released in April 2020. https://t.co/JiURHza3ff https://t.co/GigV0LGWWH https://t.co/yiPs9W1CBn', 'World Health Organization (WHO)', 'Sat Sep 25 12:07:17 +0000 2021', ['COVID19'], 223, 74, 'https://twitter.com/WHO/status/1441736058421477381', 1441736058421477381]\n",
      "\n",
      "['RT @WHOAFRO: üì∫ LIVE: @WHOAFRO press briefing on the #COVID19 pandemic, genome sequencing and COVID-19 variants in #Africa. Dr @MoetiTshidi‚Ä¶', 'World Health Organization (WHO)', 'Thu Sep 09 10:03:33 +0000 2021', ['COVID19', 'Africa'], 0, 45, 'https://twitter.com/WHO/status/1435906715497766918', 1435906715497766918]\n",
      "\n",
      "[\"RT @WHOAFRO: Join tomorrow's @WHOAFRO LIVE press briefing on the #COVID19 pandemic, genome sequencing and COVID-19 variants in #Africa. Dr‚Ä¶\", 'World Health Organization (WHO)', 'Wed Sep 08 13:38:53 +0000 2021', ['COVID19', 'Africa'], 0, 51, 'https://twitter.com/WHO/status/1435598519595843585', 1435598519595843585]\n",
      "\n",
      "\n",
      "======================\n",
      "Top 20 results out of 41 for the searched query (Health risk):\n",
      "\n",
      "[\"It's International Day for Disaster Risk Reduction\\n\\n#OpenWHO has launched a multi-tiered core curriculum to help equip you with the competencies needed to work within public health emergency response.\\n\\nStart learning today &amp; be #Ready4Response:\\nüëâ https://t.co/hBFFOF0xKL https://t.co/fgZY22RWuS\", 'World Health Organization (WHO)', 'Wed Oct 13 09:15:58 +0000 2021', ['OpenWHO', 'Ready4Response'], 52, 16, 'https://twitter.com/WHO/status/1448215930178310144', 1448215930178310144]\n",
      "\n",
      "[\"It's International Day for Disaster Risk Reduction\\n \\nTo better respond to emergencies countries must:\\n‚úÖ invest in health care systems\\n‚úÖ achieve gender equity\\n‚úÖ protect marginalised groups\\n‚úÖ ensure ready &amp; equitable access to supplies\\n \\nA strong &amp; resilient health system is üîë https://t.co/5NALyjIymp\", 'World Health Organization (WHO)', 'Wed Oct 13 07:53:28 +0000 2021', [], 300, 109, 'https://twitter.com/WHO/status/1448195167048118274', 1448195167048118274]\n",
      "\n",
      "[\"WHO's 10 calls for #ClimateAction‚ùóÔ∏è\\n\\n1‚É£ Commit to a healthy recovery\\n2‚É£ Place health at the ‚ù§Ô∏è of the climate talks\\n3‚É£ Harness the health benefits of climate action\\n4‚É£ Build health resilience to climate risks\\n5‚É£ Create greener &amp; healthier energy systems\\n\\nüëâhttps://t.co/WXMdMgPSWv https://t.co/COMZeBQGXZ\", 'World Health Organization (WHO)', 'Mon Oct 11 17:03:39 +0000 2021', ['ClimateAction'], 176, 66, 'https://twitter.com/WHO/status/1447608850899742723', 1447608850899742723]\n",
      "\n",
      "['To achieve the global #COVID19 vaccination targets, there should be a 3-step vaccination approach in every country:\\n1‚É£ First all older adults, health workers &amp; high-risk groups of all ages\\n2‚É£ Followed by the full adult age group\\n3‚É£ Then all adolescents\\n\\nüëâ https://t.co/TIshOPIbiO https://t.co/IEgz5P1ygf', 'World Health Organization (WHO)', 'Thu Oct 07 16:49:37 +0000 2021', ['COVID19'], 121, 31, 'https://twitter.com/WHO/status/1446155766541520896', 1446155766541520896]\n",
      "\n",
      "['@DrTedros @antonioguterres \"#VaccinEquity will accelerate the end of the #COVID19 pandemic. Achieving WHO‚Äôs vaccine equity targets will substantially increase population immunity globally, protect health systems, enable economies to fully restart, and reduce the risk of new variants emerging\"-@DrTedros', 'World Health Organization (WHO)', 'Thu Oct 07 13:53:50 +0000 2021', ['VaccinEquity', 'COVID19'], 238, 54, 'https://twitter.com/WHO/status/1446111530374733836', 1446111530374733836]\n",
      "\n",
      "['@DrTedros @antonioguterres \"We must remember that #COVID19 vaccines are a powerful tool, but not the only one ‚Äì all countries must continue with a comprehensive, risk-based approach of public health and social measures, in combination with equitable vaccination\"-@DrTedros', 'World Health Organization (WHO)', 'Thu Oct 07 13:53:20 +0000 2021', ['COVID19'], 245, 80, 'https://twitter.com/WHO/status/1446111402423316480', 1446111402423316480]\n",
      "\n",
      "['@DrTedros @antonioguterres \"Contracts are in place for the remaining 5 billion doses. But it‚Äôs critical that those doses go where they are needed most ‚Äì with priority given to older people, health workers and other at-risk groups\"-@DrTedros #COVID19 #VaccinEquity https://t.co/ByGl2CCvLk', 'World Health Organization (WHO)', 'Thu Oct 07 13:51:34 +0000 2021', ['COVID19', 'VaccinEquity'], 161, 39, 'https://twitter.com/WHO/status/1446110956140969987', 1446110956140969987]\n",
      "\n",
      "['@UNFPA For every woman who dies of ü§∞üèº related causes, many more suffer from disabilities and ill-health that can last a lifetime. \\n\\n#COVID19 has caused major disruptions to health services that have exacerbated such risks particularly for vulnerable üë©üèæüë©üèº\\n\\nhttps://t.co/DhTF3jxQB0 https://t.co/O2xeoEoEUo', 'World Health Organization (WHO)', 'Tue Oct 05 12:14:54 +0000 2021', ['COVID19'], 193, 54, 'https://twitter.com/WHO/status/1445361855241859075', 1445361855241859075]\n",
      "\n",
      "['#PrimaryHealthCare provides the first line of defense &amp; response to keep people safe &amp; healthy by strengthening health service delivery, essential public health functions and emergency risk management, and by involving communities in decisions about their health. https://t.co/edb5C5qFdO', 'World Health Organization (WHO)', 'Thu Sep 30 14:14:13 +0000 2021', ['PrimaryHealthCare'], 136, 46, 'https://twitter.com/WHO/status/1443579942881558541', 1443579942881558541]\n",
      "\n",
      "[\"Why does #ClimateChange put the health of billions at risk of diseases? What will happen when new areas of the world are hot and humid enough to support pathogen-carrying mosquitoes ü¶ü?\\n\\nFind out in the üÜï episode of the 'EYE on #YellowFever' podcast:\\nüîâ https://t.co/ocNf6vDRQr https://t.co/fdqMj8Ry53\", 'World Health Organization (WHO)', 'Wed Sep 29 10:37:09 +0000 2021', ['ClimateChange', 'YellowFever'], 146, 53, 'https://twitter.com/WHO/status/1443162929709395971', 1443162929709395971]\n",
      "\n",
      "[\"#Breastfeeding ü§± is a critical first #FoodSystem that ensures nutrition, health &amp; development of üë∂.\\n\\nIt's sustainable, not for profit &amp; it helps reduce:\\nüìâpreventable deaths\\nüìâthe risk of noncommunicable diseases\\nüìâthe risk of overweight/obesity\\n\\nüëâhttps://t.co/0MM8lIxZAx https://t.co/lphfIbfaYt\", 'World Health Organization (WHO)', 'Thu Sep 23 15:52:59 +0000 2021', ['Breastfeeding', 'FoodSystem'], 139, 52, 'https://twitter.com/WHO/status/1441068084022894592', 1441068084022894592]\n",
      "\n",
      "['@DrTedros @WHOEMRO \"Over the past 20 years, significant health gains have been made in #Afghanistan, in reducing maternal and child mortality, to #EndPolio, and more. Those gains are now at severe risk, with the country‚Äôs health system on the brink of collapse\"-@DrTedros https://t.co/owkLtd4I3V', 'World Health Organization (WHO)', 'Thu Sep 23 09:26:18 +0000 2021', ['Afghanistan', 'EndPolio'], 155, 93, 'https://twitter.com/WHO/status/1440970770860187648', 1440970770860187648]\n",
      "\n",
      "['@DrTedros @WHOEMRO \"I must say I am deeply concerned by the impact of the current crisis on the health and wellbeing of #Lebanon‚Äôs people, and the risks we face of losing the health gains that Lebanon had made over the last decades\"-@DrTedros https://t.co/TTUCqTuO62', 'World Health Organization (WHO)', 'Thu Sep 23 09:18:46 +0000 2021', ['Lebanon'], 36, 12, 'https://twitter.com/WHO/status/1440968874644676609', 1440968874644676609]\n",
      "\n",
      "['\"This is not a job for the health sector alone. It requires an all-of-government and all-of-society approach to improve the governance of air quality, the monitoring of #airpollution risks, and the engagement of all economic sectors in reducing emissions\"-@DrTedros', 'World Health Organization (WHO)', 'Wed Sep 22 13:30:11 +0000 2021', ['airpollution'], 201, 43, 'https://twitter.com/WHO/status/1440669757275922441', 1440669757275922441]\n",
      "\n",
      "[\"#BeirutBlast &amp; the current economic crisis in #Lebanon have increased poverty across the country &amp; are putting health sector at risk of collapse. @DrTedros &amp; @WHOEMRO Director reiterated @WHO's commitment in supporting the health system &amp; the people of üá±üáß: https://t.co/xvrdG3Ir0g https://t.co/dPNPCjwt8s\", 'World Health Organization (WHO)', 'Sun Sep 19 12:53:51 +0000 2021', ['BeirutBlast', 'Lebanon'], 394, 109, 'https://twitter.com/WHO/status/1439573450067165190', 1439573450067165190]\n",
      "\n",
      "['Venomous #snakebite üêç is a serious public health problem in rural areas of tropical &amp; sub-tropical countries in Africa, the Middle-East, Asia, Oceania and Latin America. \\nThere, the risk of snakebite is a daily concern, especially for rural and peri-urban communities https://t.co/sqVPfRBEZV', 'World Health Organization (WHO)', 'Sat Sep 18 22:20:52 +0000 2021', ['snakebite'], 233, 71, 'https://twitter.com/WHO/status/1439353759604387841', 1439353759604387841]\n",
      "\n",
      "[\"It's #WorldPatientSafetyDay\\n \\nSpeak to your health worker on how you can reduce safety risks during pregnancy and around the time of #childbirth.\\n \\nüëâhttps://t.co/gtqAmFysRl https://t.co/IrJxuouyN3\", 'World Health Organization (WHO)', 'Fri Sep 17 08:37:03 +0000 2021', ['WorldPatientSafetyDay', 'childbirth'], 188, 58, 'https://twitter.com/WHO/status/1438784050249015296', 1438784050249015296]\n",
      "\n",
      "['@DrTedros \"However, premature relaxing of public health and social measures is putting unvaccinated and immunocompromised people at extreme risk\"-@DrTedros https://t.co/HvlUy9JdL3', 'World Health Organization (WHO)', 'Wed Sep 08 14:35:19 +0000 2021', [], 67, 44, 'https://twitter.com/WHO/status/1435612719454040066', 1435612719454040066]\n",
      "\n",
      "['‚ñ∂Ô∏è Are you planning to #QuitTobacco during the pandemic?\\n‚ñ∂Ô∏è What risk does #COVID19 pose to a tobacco use?\\n\\nLearn how the tobacco industry lured people to consume tobacco during the pandemic. Dr @HebeGouda explains the health benefits of quitting tobacco in #ScienceIn5. https://t.co/L4LPsdHSzq', 'World Health Organization (WHO)', 'Sun Sep 05 10:32:10 +0000 2021', ['QuitTobacco', 'COVID19', 'ScienceIn5'], 253, 92, 'https://twitter.com/WHO/status/1434464365768429576', 1434464365768429576]\n",
      "\n",
      "['WHO recommends that patients who are at risk of severe #COVID19 have their oxygen levels monitored using a pulse oximeter at least twice a day.\\nThese levels should be reported to your health worker. https://t.co/0GtJqlJEjw', 'World Health Organization (WHO)', 'Fri Sep 03 12:58:33 +0000 2021', ['COVID19'], 196, 92, 'https://twitter.com/WHO/status/1433776429745967107', 1433776429745967107]\n",
      "\n",
      "\n",
      "======================\n",
      "Top 20 results out of 29 for the searched query (World pandemic):\n",
      "\n",
      "['\"The #COVIDSummit\\xa0also included a discussion on the steps needed to prevent and better prepare for the next pandemic. The following 5‚É£\\xa0actions must be at the heart of the world‚Äôs common drive to keep people safe, serve the vulnerable and promote health\"- @DrTedros', 'World Health Organization (WHO)', 'Fri Sep 24 18:01:04 +0000 2021', ['COVIDSummit'], 34, 13, 'https://twitter.com/WHO/status/1441462703583760384', 1441462703583760384]\n",
      "\n",
      "['\"Commitments alone won‚Äôt save lives, stop transmission, immunize people, scale up manufacturing capacity, and ready the world to prevent future health emergencies. What is needed now is for commitments to turn into immediate actions to equitably end the pandemic\"- @DrTedros', 'World Health Organization (WHO)', 'Fri Sep 24 18:03:43 +0000 2021', [], 81, 23, 'https://twitter.com/WHO/status/1441463370331435011', 1441463370331435011]\n",
      "\n",
      "['\"The world is at a perilous point in this pandemic. \\n\\nWe have just passed the tragic milestone of 4 million recorded #COVID19 deaths, which likely underestimates the overall toll\"-@DrTedros', 'World Health Organization (WHO)', 'Wed Jul 07 13:18:53 +0000 2021', ['COVID19'], 85, 52, 'https://twitter.com/WHO/status/1412763048071344128', 1412763048071344128]\n",
      "\n",
      "['@DrTedros \"From a moral, epidemiological or economic point view, now is the time for the world to come together to tackle this pandemic collectively\"-@DrTedros #COVID19 #VaccinEquity \\nhttps://t.co/ip4HvF2SRR', 'World Health Organization (WHO)', 'Wed Jul 07 13:22:22 +0000 2021', ['COVID19', 'VaccinEquity'], 91, 50, 'https://twitter.com/WHO/status/1412763926039830534', 1412763926039830534]\n",
      "\n",
      "['RT @DrTedros: The world is at a perilous point in the #COVID19 pandemic. We have just passed the tragic milestone of 4 million recorded dea‚Ä¶', 'World Health Organization (WHO)', 'Wed Jul 07 20:47:34 +0000 2021', ['COVID19'], 0, 439, 'https://twitter.com/WHO/status/1412875962795143169', 1412875962795143169]\n",
      "\n",
      "['\"For almost 18 months now, the world‚Äôs health and care workers have been at the forefront of the #COVID19 pandemic. \\nThey have reminded us almost daily that they are incredible people doing incredible jobs under incredible circumstances.\"-@DrTedros at #GenerationEquality', 'World Health Organization (WHO)', 'Thu Jul 01 14:29:00 +0000 2021', ['COVID19', 'GenerationEquality'], 419, 95, 'https://twitter.com/WHO/status/1410606368466235395', 1410606368466235395]\n",
      "\n",
      "['@DrTedros @jensspahn @ACTAccelerator \"If the üåç continues down the same road, it will continue heading towards the same destination, which is an unsafe world, and another devastating pandemic is inevitable. We need a new approach, and a new way of doing things\"-@DrTedros #PandemicTreaty', 'World Health Organization (WHO)', 'Thu Jul 15 12:26:53 +0000 2021', ['PandemicTreaty'], 78, 26, 'https://twitter.com/WHO/status/1415649064243417090', 1415649064243417090]\n",
      "\n",
      "['@Olympics @DrTedros \"Anyone who thinks #COVID19 the pandemic is over because it‚Äôs over where they live is living in a fool‚Äôs paradise. Vaccines are powerful and essential tools. But the world has not used them well\"-@DrTedros #Tokyo2020 #AGoal4All \\n\\nhttps://t.co/yHGo73V5y7', 'World Health Organization (WHO)', 'Wed Jul 21 00:24:48 +0000 2021', ['COVID19', 'Tokyo2020', 'AGoal4All'], 122, 67, 'https://twitter.com/WHO/status/1417641674734456834', 1417641674734456834]\n",
      "\n",
      "['@Olympics @DrTedros @Tokyo2020 @Paralympics \"Ending the #COVID19 pandemic is a choice all of us can make. And there is something all of us can do: governments, companies, civil society and the people of the world\"-@DrTedros #Tokyo2020 #AGoal4All \\n\\nhttps://t.co/JRiZg2v2nM', 'World Health Organization (WHO)', 'Wed Jul 21 00:59:25 +0000 2021', ['COVID19', 'Tokyo2020', 'AGoal4All'], 53, 18, 'https://twitter.com/WHO/status/1417650385288843264', 1417650385288843264]\n",
      "\n",
      "['@Olympics @DrTedros @Tokyo2020 @Paralympics @g20org \"If they choose to, the world‚Äôs leading economies could bring the pandemic under control globally in a matter of months by sharing doses through #COVAX, funding the @ACTAccelerator, &amp; incentivizing manufacturers to do whatever it takes to scale up production\"-@DrTedros #AGoal4All', 'World Health Organization (WHO)', 'Wed Jul 21 01:02:36 +0000 2021', ['COVAX', 'AGoal4All'], 62, 30, 'https://twitter.com/WHO/status/1417651189605453826', 1417651189605453826]\n",
      "\n",
      "['\"The first part of that hope was realized ‚Äì the development and approval of several safe and effective vaccines in record time has given the world real hope of bringing the [#COVID19] pandemic under control.\"-@DrTedros at #RC71AFRO', 'World Health Organization (WHO)', 'Tue Aug 24 09:03:51 +0000 2021', ['COVID19', 'RC71AFRO'], 27, 6, 'https://twitter.com/WHO/status/1430093487110828052', 1430093487110828052]\n",
      "\n",
      "['At the 76th #UNGA, WHO is urging world leaders to\\n\\n1‚É£ guarantee equitable access to #COVID19 vaccines &amp; life-saving tools\\n2‚É£ ensure better pandemic preparedness\\n3‚É£ get the @GlobalGoalsUN back on track\\n\\nRead more üëâhttps://t.co/gQ60gbT6WP https://t.co/aXObgfbcNi', 'World Health Organization (WHO)', 'Tue Sep 21 08:57:50 +0000 2021', ['UNGA', 'COVID19'], 467, 156, 'https://twitter.com/WHO/status/1440238829999329281', 1440238829999329281]\n",
      "\n",
      "[\"WHO &amp; partners continue responding to #COVID19 around the world:\\n\\nüìç implementing Resurgence Response Plan in #Uganda üá∫üá¨\\nüìç strengthening #Uzbekistan üá∫üáø's pandemic preparedness\\nüìç delivering medical supplies &amp; training to #Guatemala üá¨üáπ\\n\\nüëâhttps://t.co/uElpVwoohK #WHOImpact https://t.co/tEBkEzzXSc\", 'World Health Organization (WHO)', 'Sat Sep 25 18:07:05 +0000 2021', ['COVID19', 'Uganda', 'Uzbekistan', 'Guatemala', 'WHOImpact'], 108, 28, 'https://twitter.com/WHO/status/1441826605303681026', 1441826605303681026]\n",
      "\n",
      "['\"Even as we remain focused on ending the pandemic, WHO is moving forward with plans to understand its origins. \\nLast Friday, we issued an open call to scientists around the world to apply to the new Strategic Advisory Group for the Origins of Novel Pathogens, or SAGO.\"-@DrTedros https://t.co/8Ct7RL1LwS', 'World Health Organization (WHO)', 'Wed Aug 25 15:21:12 +0000 2021', [], 59, 26, 'https://twitter.com/WHO/status/1430550837412208641', 1430550837412208641]\n",
      "\n",
      "['\"You will also be discussing the challenges facing our organization, including the challenge of sustainable financing.\\nThe pandemic has shown that the world needs an empowered and sustainably financed WHO at the centre of the global health architecture.\"-@DrTedros at #RC71AFRO', 'World Health Organization (WHO)', 'Tue Aug 24 09:34:08 +0000 2021', ['RC71AFRO'], 31, 9, 'https://twitter.com/WHO/status/1430101107045453824', 1430101107045453824]\n",
      "\n",
      "['The new story drew from the responses to a survey of more than 5000 children, parents, caregivers and teachers from around the world who were asked to describe the challenges they continue to face in the second year of the #COVID19 pandemic https://t.co/JiURHzrEDP https://t.co/U5mvGbqPSN', 'World Health Organization (WHO)', 'Mon Sep 27 06:57:53 +0000 2021', ['COVID19'], 126, 25, 'https://twitter.com/WHO/status/1442382972125069312', 1442382972125069312]\n",
      "\n",
      "['\"Even as we continue our work to understand how this pandemic started, we are also moving ahead with plans to strengthen the world‚Äôs defences against future epidemics and pandemics.\"-@DrTedros', 'World Health Organization (WHO)', 'Wed Aug 25 15:26:01 +0000 2021', [], 64, 19, 'https://twitter.com/WHO/status/1430552048131522564', 1430552048131522564]\n",
      "\n",
      "['\"The #COVID19 pandemic has revealed two critical areas in which the world needs to do far more to bolster global health security: strengthening and sharing.\"-@DrMikeRyan', 'World Health Organization (WHO)', 'Wed Jul 28 20:48:43 +0000 2021', ['COVID19'], 25, 11, 'https://twitter.com/WHO/status/1420486398243745795', 1420486398243745795]\n",
      "\n",
      "['\"With the @UN General Assembly in September, the @g20org Summit in October and the Special Session of the World Health Assembly in November, the next three months will be a critical period for shaping the future of pandemic preparedness and response.\"-@DrTedros', 'World Health Organization (WHO)', 'Wed Aug 25 15:41:09 +0000 2021', [], 39, 15, 'https://twitter.com/WHO/status/1430555858585403393', 1430555858585403393]\n",
      "\n",
      "['\"But above and beyond improved mechanisms, improved tools and improved financing, the world needs an improved framework for pandemic preparedness and response.\"-@DrMikeRyan', 'World Health Organization (WHO)', 'Wed Jul 28 20:55:32 +0000 2021', [], 18, 5, 'https://twitter.com/WHO/status/1420488114842312707', 1420488114842312707]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Insert your query (i.e.: Computer Science):\\n\")\n",
    "num_queries = 5\n",
    "#queries = [None]*num_queries\n",
    "retrieved_docs = {} #keys will be the query id\n",
    "queries = [\n",
    "    'Covid vaccine',\n",
    "    'International health',\n",
    "    'Covid pandemics',\n",
    "    'Health risk',\n",
    "    'World pandemic'\n",
    "] #  Comment this line if you want to write your own queries\n",
    "\n",
    "for q_id in range(num_queries):\n",
    "    #query = input()\n",
    "    query = queries[q_id] # Comment this line and uncomment the line above if you want to write your own queries\n",
    "    ranked_docs, doc_scores = search_tf_idf(query, index)\n",
    "    top = 20\n",
    "    queries[q_id] = query\n",
    "    if ranked_docs:\n",
    "        print(f\"\\n======================\\nTop {top} results out of {len(ranked_docs)} for the searched query ({query}):\\n\")\n",
    "        retrieved_docs[q_id] = doc_scores[:top]\n",
    "        for d_id in ranked_docs[:top]:\n",
    "            print(f\"{id_index[d_id]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqPcKef7gKfq"
   },
   "source": [
    "<font size=\"+5\" color=\"seagreen\">3. Evaluation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"lightgreen\">3.1 Ground truth</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_amount(id_index):\n",
    "    \"\"\"\n",
    "    Input: A dictionary of the retrieved docs of a query.\n",
    "    Output: The median number of retweets and likes found in the dictionary\n",
    "    \"\"\"\n",
    "    median_retweets = []\n",
    "    median_likes = []\n",
    "    for doc_id in id_index:\n",
    "        doc = id_index[doc_id]\n",
    "        median_retweets.append(doc[-2])\n",
    "        median_likes.append(doc[-3])\n",
    "    return np.percentile(median_retweets, 50),np.percentile(median_likes, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_y_true(doc_info,median_retweets,median_likes):\n",
    "    \"\"\"\n",
    "    Input: A document info and the median number of retweets and likes found in a dictionary of all the tweets\n",
    "    Output: 0 if the document is not relevant a 1 if the document is relevant, all of it based on the number of retweets and likes\n",
    "    of the document\n",
    "    \"\"\"   \n",
    "    num_retweets = doc_info[-2]\n",
    "    num_likes = doc_info[-3]\n",
    "    threshold = 0.1 \n",
    "    if num_retweets >= median_likes or num_likes >= median_likes:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3VCA2jqhgKfr",
    "outputId": "878389e6-c050-4db8-e85c-302569e21516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation:\n",
      "\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U50'), dtype('<U50')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19684/1285399735.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evaluation:\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmedian_retweets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmedian_likes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmedian_amount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#The line abive is to get the median number of retweets and the median number of likes af all the tweets respectively\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mq_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mretrieved_docs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19684/3119283666.py\u001b[0m in \u001b[0;36mmedian_amount\u001b[1;34m(id_index)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mmedian_retweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mmedian_likes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedian_retweets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedian_likes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpercentile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IRWA\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, interpolation, keepdims)\u001b[0m\n\u001b[0;32m   3865\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_quantile_is_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3866\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Percentiles must be in the range [0, 100]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3867\u001b[1;33m     return _quantile_unchecked(\n\u001b[0m\u001b[0;32m   3868\u001b[0m         a, q, axis, out, overwrite_input, interpolation, keepdims)\n\u001b[0;32m   3869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IRWA\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, interpolation, keepdims)\u001b[0m\n\u001b[0;32m   3984\u001b[0m                         interpolation='linear', keepdims=False):\n\u001b[0;32m   3985\u001b[0m     \u001b[1;34m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3986\u001b[1;33m     r, k = _ureduce(a, func=_quantile_ureduce_func, q=q, axis=axis, out=out,\n\u001b[0m\u001b[0;32m   3987\u001b[0m                     \u001b[0moverwrite_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverwrite_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3988\u001b[0m                     interpolation=interpolation)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IRWA\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3562\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3564\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3565\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IRWA\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   4110\u001b[0m         \u001b[0mx_above\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_above\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4112\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lerp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_below\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_above\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_above\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m     \u001b[1;31m# if any slice contained a nan, then all results on that slice are also nan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IRWA\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_lerp\u001b[1;34m(a, b, t, out)\u001b[0m\n\u001b[0;32m   4007\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_lerp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4008\u001b[0m     \u001b[1;34m\"\"\" Linearly interpolate from a to b by a factor of t \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4009\u001b[1;33m     \u001b[0mdiff_b_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4010\u001b[0m     \u001b[1;31m# asanyarray is a stop-gap until gh-13105\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4011\u001b[0m     \u001b[0mlerp_interpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff_b_a\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U50'), dtype('<U50')) -> None"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation:\\n\")\n",
    "first = True\n",
    "median_retweets,median_likes = median_amount(id_index)\n",
    "#The line abive is to get the median number of retweets and the median number of likes af all the tweets respectively\n",
    "for q_id in retrieved_docs.keys():\n",
    "    docs_id = []\n",
    "    y = []\n",
    "    bin_y = []\n",
    "    for doc in retrieved_docs[q_id]:\n",
    "        if first:\n",
    "            docs_id.append(doc[1])\n",
    "            y.append(doc[0])\n",
    "            bin_y.append(bin_y_true(id_index[doc[1]],median_retweets,median_likes))\n",
    "        else:\n",
    "            data = {'q_id':q_id,'doc_id':doc[1] , 'predicted_relevance':doc[0],'bin_y_true':bin_y_true(id_index[doc[1]],median_retweets,median_likes)}\n",
    "            search_results = search_results.append(data,ignore_index=True)\n",
    "    if first:\n",
    "        data = {'q_id':q_id,'doc_id':docs_id , 'predicted_relevance':y,'bin_y_true':bin_y}\n",
    "        search_results = pd.DataFrame(data)\n",
    "        first = False\n",
    "display(search_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAtPY9VdgKfr"
   },
   "source": [
    "<font size=\"+2\" color=\"lightgreen\">3.2 Evaluation techniques </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"greenyellow\">3.2.1 Precision@K (P@K) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_UG8JfegKfr"
   },
   "outputs": [],
   "source": [
    "def precision_at_k(y_true, y_score, k=10):\n",
    "    '''    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "    \n",
    "    '''    \n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)[:k]\n",
    "    relevant = np.sum(y_true)\n",
    "    \n",
    "    return relevant/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"greenyellow\">3.2.2 Average Precision@K (P@K) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27yrXYj1gKfs"
   },
   "outputs": [],
   "source": [
    "def avg_precision_at_k(y_true, y_score, k=10):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    average precision @k : float\n",
    "    '''\n",
    "    \n",
    "    gtp = np.sum(y_true == 1)\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])           \n",
    "\n",
    "    ## if all docs are not relevant\n",
    "    if gtp==0:\n",
    "        return 0\n",
    "    n_relevant_at_i = 0\n",
    "    prec_at_i = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            n_relevant_at_i += 1\n",
    "            prec_at_i += n_relevant_at_i/(i + 1)\n",
    "            \n",
    "    return prec_at_i/gtp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"greenyellow\">3.2.3 Mean Average Precision (MAP) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwpAW74sgKfs"
   },
   "outputs": [],
   "source": [
    "def map_at_k(search_res, k=10):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_res: search results dataset containing:\n",
    "        q_id: query id.\n",
    "        doc_id: document id.\n",
    "        predicted_relevance: relevance predicted through LightGBM.\n",
    "        y_true: actual score of the document for the query (ground truth).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean average precision @k : float\n",
    "    '''\n",
    "    avp = []\n",
    "    for q in search_res['q_id'].unique(): #loop over all query id\n",
    "        curr_data = search_res[search_res['q_id'] == q]  # select data for current query\n",
    "        avp.append(avg_precision_at_k(np.array(curr_data['bin_y_true']), np.array(curr_data['predicted_relevance']), k)) #append average precision for current query\n",
    "    return np.sum(avp)/len(avp) # return mean average precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"greenyellow\">3.2.4 Mean Reciprocal Rank (MRR) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Txr5JoMgKfs"
   },
   "outputs": [],
   "source": [
    "def rr_at_k(y_true, y_score, k=10):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Reciprocal Rank for qurrent query\n",
    "    '''\n",
    "\n",
    "    order = np.argsort(y_score)[::-1] # get the list of indexes of the predicted score sorted in descending order.\n",
    "    y_true = np.take(y_true, order[:k]) # sort the actual relevance label of the documents based on predicted score and take first k.\n",
    "\n",
    "    if np.sum(y_true) == 0: # if there are not relevant doument return 0\n",
    "        return 0\n",
    "    return 1/(np.argmax(y_true == 1) + 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"greenyellow\">3.2.5 Normalized Discounted Cumulative Gain (NDGC) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOT06VHGgKft"
   },
   "outputs": [],
   "source": [
    "def dcg_at_k(y_true, y_score,  k=10):\n",
    "    order = np.argsort(y_score)[::-1] # get the list of indexes of the predicted score sorted in descending order.\n",
    "    y_true = np.take(y_true, order[:k]) # sort the actual relevance label of the documents based on predicted score and take first k.\n",
    "    gain = (2**y_true) - 1 # Compute gain \n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2) # Compute denominator\n",
    "    return np.sum(gain / discounts) #return dcg@k\n",
    "\n",
    "\n",
    "def ndcg_at_k(y_true, y_score, k=10):    \n",
    "    dcg_max = dcg_at_k(y_true, y_true, k) # Ideal dcg\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return np.round(dcg_at_k(y_true, y_score, k)/dcg_max,4)  # return ndcg@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7XdKJREgKft",
    "outputId": "36a26980-24f4-4ce6-f2cd-6ab8fc51a9b1"
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate results of different evaluation methods\"\"\"\n",
    "\n",
    "current_query = 0\n",
    "current_query_res = search_results[search_results[\"q_id\"] == current_query] \n",
    "k = 10\n",
    "print(\"Evaluation about query 0:\",queries[current_query],\"\\n\")\n",
    "\n",
    "print(\"==> Precision@{}: {}\\n\".format(k, precision_at_k(current_query_res[\"bin_y_true\"],\n",
    "                                                        current_query_res[\"predicted_relevance\"],\n",
    "                                                        k)))\n",
    "\n",
    "print(\"==> AveragePrecision@{}: {}\\n\".format(k,avg_precision_at_k(np.array(current_query_res[\"bin_y_true\"]),\n",
    "                                                                  np.array(current_query_res[\"predicted_relevance\"]), \n",
    "                                                                  150)))\n",
    "\n",
    "print(\"==> MeanAveragePrecision@{}: {}\\n\".format(k, map_at_k(search_results,10)))\n",
    "\n",
    "\"\"\"Generate Reciprocal Rank\n",
    "\n",
    "For the top 3, 5 and 10 queries scores. \n",
    "\n",
    "First for every query we: Get its labels,the predicted score, calculate its RR score and append at to all our\n",
    "previous scores.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "mrr = {}\n",
    "for k in [3,5,10]:\n",
    "    RRs = []\n",
    "    for q in search_results['q_id'].unique(): \n",
    "        labels = np.array(search_results[search_results['q_id'] == q] ['bin_y_true']) \n",
    "        scores = np.array(search_results[search_results['q_id'] == q] ['predicted_relevance'])\n",
    "        RRs.append(rr_at_k(labels, scores, k)) \n",
    "    mrr[k] = np.round(float(sum(RRs)/len(RRs)) ,4)\n",
    "\n",
    "print(\"==> MeanReciprocalRank: {}\\n\".format(mrr[k]))\n",
    "\n",
    "labels = np.array(search_results[search_results['q_id'] == q_id][\"bin_y_true\"])\n",
    "scores = np.array(search_results[search_results['q_id'] == q_id][\"predicted_relevance\"])\n",
    "ndcg_k = np.round(ndcg_at_k(labels, scores, k),4)\n",
    "\n",
    "print(\"==> NormalizedDiscountedCumulativeGain@{} for query with q_id={}: {}\\n\".format(k,current_query,ndcg_k))\n",
    "\n",
    "\n",
    "ndcgs = []\n",
    "k=10\n",
    "for q in search_results['q_id'].unique(): # loop over all query ids\n",
    "    labels = np.array(search_results[search_results['q_id'] == q]['bin_y_true']) ## get labels for current query\n",
    "    scores = np.array(search_results[search_results['q_id'] == q]['predicted_relevance']) # get predicted score for current query\n",
    "    ndcgs.append(np.round(ndcg_at_k(labels, scores, k), 4)) # append NDCG for current query\n",
    "\n",
    "avg_ndcg = np.round(float(sum(ndcgs)/len(ndcgs)),4) # Compute average NDCG\n",
    "print(\"==> Average ndcg@{} (considering all queries): {}\".format(k,avg_ndcg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtMtUHlLgKfu"
   },
   "source": [
    "<font size=\"+2\" color=\"lightgreen\">3.3 Word 2 Vec</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDh9Q3JfgKfu"
   },
   "outputs": [],
   "source": [
    "words = [[word for word in index.keys()]]  # Generate vocabulary to be used in TSNE\n",
    "\n",
    "word2vec = Word2Vec(words, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nY0yiQYvgKfu"
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate word embeddings\"\"\"\n",
    "\n",
    "keys = ['covid','vaccine','economic', 'cure']\n",
    "keys = [process_tweet(word) for word in keys]\n",
    "embedding_clusters = []\n",
    "word_clusters = []\n",
    "\n",
    "for word in keys:\n",
    "    embeddings = []\n",
    "    words = []\n",
    "    for similar_word, _ in word2vec.wv.most_similar(word, topn=50):\n",
    "        words.append(similar_word)\n",
    "        embeddings.append(word2vec.wv[similar_word])\n",
    "        \n",
    "    embedding_clusters.append(embeddings)\n",
    "    word_clusters.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mk-6O4ZMgKfu",
    "outputId": "bc26f343-239b-4dee-e1ef-e37df3b371fc"
   },
   "outputs": [],
   "source": [
    "embedding_clusters = np.array(embedding_clusters)\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=1000, random_state=32,verbose=1)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JVXrZiIgKfv"
   },
   "outputs": [],
   "source": [
    "def tsne_plot_similar_words(title, labels, embedding_clusters, word_clusters, a, filename=None):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
    "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
    "        x = embeddings[:, 0]\n",
    "        y = embeddings[:, 1]\n",
    "        plt.scatter(x, y, c=color, alpha=a, label=label)\n",
    "        for i, word in enumerate(words):\n",
    "            plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2),\n",
    "                         textcoords='offset points', ha='right', va='bottom', size=8)\n",
    "    plt.legend(loc=4)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    if filename:\n",
    "        plt.savefig(filename, format='png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JUrC2RLgKfv",
    "outputId": "bff20827-bb17-423e-b4f0-3e861f944080"
   },
   "outputs": [],
   "source": [
    "tsne_plot_similar_words(\"Similar words from WHO's twitter account\", \n",
    "                        keys, \n",
    "                        embeddings_en_2d, \n",
    "                        word_clusters, \n",
    "                        0.7,\n",
    "                        filename='similar_words.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+0.5\" color=\"indianred\">1. Ground truth is a bit poor, 2. Not outstanding results, 3. Use conjunctive queries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\" color=\"seagreen\">4. Ranking</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSOwTs6lgKfp"
   },
   "outputs": [],
   "source": [
    "def rank_documents_own(terms, docs, index, idf, tf, title_index):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    title_index -- mapping between page id and page title\n",
    "    \n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) \n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms) \n",
    "\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "    \n",
    "    # retrieve maximal and minimal number of likes and rts so we can normalize \n",
    "    # the values to generate scores using a min-max normalization\n",
    "    \n",
    "    likes = []\n",
    "    rts = []\n",
    "    for _,docs_ in index.items():\n",
    "        for doc in docs_:\n",
    "            tweet = id_index[doc]\n",
    "            likes_n = tweet[4]\n",
    "            rts_n = tweet[5]\n",
    "\n",
    "            if likes_n not in likes:\n",
    "                likes.append(likes_n)\n",
    "\n",
    "            if rts_n not in rts:\n",
    "                rts.append(rts_n)\n",
    "                \n",
    "    max_likes = np.max(likes)\n",
    "    max_rts = np.max(rts)\n",
    "    min_likes = np.min(likes)\n",
    "    min_rts = np.min(rts)\n",
    "    \n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        # Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]=(1+np.log2(query_terms_count[term]/query_norm)) * np.log2(idf[term]) \n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc in index[term]:          \n",
    "            if doc in docs:\n",
    "                tweet = id_index[doc]\n",
    "                likes_doc = tweet[4]\n",
    "                rts_doc = tweet[5]\n",
    "                \n",
    "                likes_score = (likes_doc - min_likes)/(max_likes - min_likes)\n",
    "                rts_score = (rts_doc - min_rts)/(max_rts - min_rts)\n",
    "                doc_vectors[doc][termIndex] = ((1+np.log2(tf[term][doc])) * np.log2(idf[term]) \n",
    "                                               + likes_score \n",
    "                                               + rts_score)\n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    \n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "        query = input()\n",
    "        if not query:\n",
    "            return None\n",
    "        result_docs, doc_scores = search_tf_idf_own(query, index)\n",
    "    return result_docs, doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND8CkxgegKfq"
   },
   "outputs": [],
   "source": [
    "def search_tf_idf_own(query, index):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    first = True\n",
    "    if not query:\n",
    "        return None\n",
    "    for term in query:\n",
    "        try:\n",
    "            list_docs = index[term]\n",
    "            if first:\n",
    "                docs = set(list_docs)\n",
    "                first = False\n",
    "            else:\n",
    "                docs &= set(list_docs)\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    docs = list(docs)\n",
    "    ranked_docs, doc_scores = rank_documents_own(query, docs, index, idf, tf, id_index)\n",
    "    \n",
    "    return ranked_docs, doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Insert your query (i.e.: Computer Science):\\n\")\n",
    "num_queries = 5\n",
    "#queries = [None]*num_queries\n",
    "retrieved_docs = {} #keys will be the query id\n",
    "queries = [\n",
    "    'Covid vaccine',\n",
    "    'International health',\n",
    "    'Covid pandemics',\n",
    "    'Health risk',\n",
    "    'World pandemic'\n",
    "] #  Comment this line if you want to write your own queries\n",
    "\n",
    "for q_id in range(num_queries):\n",
    "    #query = input()\n",
    "    query = queries[q_id] # Comment this line and uncomment the line above if you want to write your own queries\n",
    "    ranked_docs, doc_scores = search_tf_idf_own(query, index)\n",
    "    top = 20\n",
    "    queries[q_id] = query\n",
    "    if ranked_docs:\n",
    "        print(f\"\\n======================\\nTop {top} results out of {len(ranked_docs)} for the searched query ({query}):\\n\")\n",
    "        retrieved_docs[q_id] = doc_scores[:top]\n",
    "        for d_id in ranked_docs[:top]:\n",
    "            print(f\"{id_index[d_id]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSOwTs6lgKfp"
   },
   "outputs": [],
   "source": [
    "def rank_documents_w2v(terms, docs, index, idf, tf, title_index, word2vec):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    docs -- list of documents, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    title_index -- mapping between page id and page title\n",
    "    \n",
    "    Returns:\n",
    "    Print the list of ranked documents\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    doc_vectors = defaultdict(lambda: [0] * len(terms)) \n",
    "    query_vector = [0] * len(terms)\n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms) \n",
    "\n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "    \n",
    "    for termIndex, term in enumerate(terms):  #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        # Compute tf*idf(normalize TF as done with documents)\n",
    "        query_vector[termIndex]=(1+np.log2(query_terms_count[term]/query_norm)) * np.log2(idf[term]) \n",
    "\n",
    "        # Generate doc_vectors for matching docs\n",
    "        for doc in index[term]:          \n",
    "            if doc in docs:\n",
    "                tweet = id_index[doc]\n",
    "                text = process_tweet(tweet[0])\n",
    "\n",
    "                cosine_sims = []\n",
    "                \n",
    "                for word in text:\n",
    "                        cosine_sims.append(word2vec.wv.similarity(word, term))\n",
    "                \n",
    "                cosine_sim = np.average(cosine_sims)\n",
    "                \n",
    "                doc_vectors[doc][termIndex] = cosine_sim\n",
    "\n",
    "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
    "    doc_scores.sort(reverse=True)\n",
    "    \n",
    "    result_docs = [x[1] for x in doc_scores]\n",
    "    if len(result_docs) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "        query = input()\n",
    "        if not query:\n",
    "            return None\n",
    "        result_docs, doc_scores = search_tf_idf_w2v(query, index)\n",
    "    return result_docs, doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND8CkxgegKfq"
   },
   "outputs": [],
   "source": [
    "def search_tf_idf_w2v(query, index, word2vec):\n",
    "    \"\"\"\n",
    "    output is the list of documents that contain any of the query terms. \n",
    "    So, we will get the list of documents for each query term, and take the union of them.\n",
    "    \"\"\"\n",
    "    query = process_tweet(query)\n",
    "    docs = set()\n",
    "    first = True\n",
    "    if not query:\n",
    "        return None\n",
    "    for term in query:\n",
    "        try:\n",
    "            list_docs = index[term]\n",
    "            if first:\n",
    "                docs = set(list_docs)\n",
    "                first = False\n",
    "            else:\n",
    "                docs &= set(list_docs)\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    docs = list(docs)\n",
    "    ranked_docs, doc_scores = rank_documents_w2v(query, docs, index, idf, tf, id_index, word2vec)\n",
    "    \n",
    "    return ranked_docs, doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Insert your query (i.e.: Computer Science):\\n\")\n",
    "num_queries = 5\n",
    "#queries = [None]*num_queries\n",
    "retrieved_docs = {} #keys will be the query id\n",
    "queries = [\n",
    "    'Covid vaccine',\n",
    "    'International health',\n",
    "    'Covid pandemics',\n",
    "    'Health risk',\n",
    "    'World pandemic'\n",
    "] #  Comment this line if you want to write your own queries\n",
    "\n",
    "for q_id in range(num_queries):\n",
    "    #query = input()\n",
    "    query = queries[q_id] # Comment this line and uncomment the line above if you want to write your own queries\n",
    "    ranked_docs, doc_scores = search_tf_idf_w2v(query, index, word2vec)\n",
    "    top = 20\n",
    "    queries[q_id] = query\n",
    "    if ranked_docs:\n",
    "        print(f\"\\n======================\\nTop {top} results out of {len(ranked_docs)} for the searched query ({query}):\\n\")\n",
    "        retrieved_docs[q_id] = doc_scores[:top]\n",
    "        for d_id in ranked_docs[:top]:\n",
    "            print(f\"{id_index[d_id]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IRWA-2021-final-project-u161675-u149891-u161819-part-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
